{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6253133",
   "metadata": {},
   "source": [
    "# Download e carregamento do dataset Amazon Fine Food Reviews\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4fa28a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import kagglehub\n",
    "import shutil\n",
    "\n",
    "def download_kaggle_dataset(dataset):\n",
    "    path = kagglehub.dataset_download(dataset)\n",
    "    \n",
    "    if not os.path.exists('./dataset'):\n",
    "        os.makedirs('./dataset')\n",
    "\n",
    "    if not os.path.exists(f\"./dataset/{dataset.split('/')[-1]}\"):\n",
    "        os.makedirs(f\"./dataset/{dataset.split('/')[-1]}\")\n",
    "\n",
    "    for file in os.listdir(path):\n",
    "        if file.endswith('.csv') or file.endswith('.json'):\n",
    "            src = os.path.join(path, file)\n",
    "            dst = os.path.join(f\"./dataset/{dataset.split('/')[-1]}\", file)\n",
    "            shutil.copy2(src, dst)  # Copies file wich are originally saved in USER/kagglehub\n",
    "            print(f\"Copied {file} to ./dataset\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9abda761",
   "metadata": {},
   "source": [
    "### Amazon Fine Food Reviews  \n",
    "Comprises over 560,000 food product reviews from Amazon, labeled with star ratings from 1 to 5. Useful for sentiment analysis, recommendation systems, and opinion mining. Reviews vary in length and detail.\n",
    "\n",
    "### Sentiment140  \n",
    "This dataset contains 1.6 million tweets labeled as positive, negative, or neutral. It is widely used for sentiment analysis tasks involving informal text and social media language. Great for training models robust to slang and emojis.\n",
    "\n",
    "### AG News Topic Classification  \n",
    "Contains 120,000 news articles categorized into 4 classes (World, Sports, Business, Sci/Tech). Widely used for topic classification benchmarks. The dataset size is about 150 MB on Kaggle.\n",
    "\n",
    "### News Category Dataset  \n",
    "Contains around 200,000 news headlines labeled with categories like politics, sports, and technology. It is ideal for multiclass text classification and topic modeling tasks. The dataset reflects real-world news distribution.\n",
    "\n",
    "### DBpedia Ontology Classification  \n",
    "Contains 560,000+ Wikipedia article abstracts labeled into 14 ontology classes. Popular for large-scale multi-class text classification. The dataset size is about 200 MB on Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c27c9381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied Reviews.csv to ./dataset\n",
      "Copied training.1600000.processed.noemoticon.csv to ./dataset\n",
      "Copied test.csv to ./dataset\n",
      "Copied train.csv to ./dataset\n",
      "Copied News_Category_Dataset_v3.json to ./dataset\n",
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/thedevastator/dbpedia-ontology-dataset?dataset_version_number=2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66.3M/66.3M [00:07<00:00, 9.27MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied test.csv to ./dataset\n",
      "Copied train.csv to ./dataset\n"
     ]
    }
   ],
   "source": [
    "download_kaggle_dataset(\"snap/amazon-fine-food-reviews\")\n",
    "download_kaggle_dataset(\"kazanova/sentiment140\")\n",
    "download_kaggle_dataset(\"amananandrai/ag-news-classification-dataset\")\n",
    "download_kaggle_dataset(\"rmisra/news-category-dataset\")\n",
    "download_kaggle_dataset(\"thedevastator/dbpedia-ontology-dataset\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
