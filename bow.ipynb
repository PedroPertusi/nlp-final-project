{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b364c0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Setup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Change this to 'amazon', 'ag', or 'imdb'\n",
    "# DATASET = 'amazon'\n",
    "# DATASET = 'ag'\n",
    "DATASET = 'imdb'\n",
    "\n",
    "TEST_SIZE = 0.2  # fraction for test set\n",
    "\n",
    "configs = {\n",
    "    'ag': {\n",
    "        'path': 'dataset/ag-news-classification-dataset',\n",
    "        'train_file': 'train.csv',\n",
    "        'test_file':  'test.csv',\n",
    "        'text_cols':  ['Title','Description'],\n",
    "        'label_col':  'Class Index',\n",
    "        'label_shift': -1,\n",
    "        'has_test_file': True\n",
    "    },\n",
    "    'amazon': {\n",
    "        'path': 'dataset/amazon-fine-food-reviews',\n",
    "        'train_file': 'Reviews.csv',\n",
    "        'test_file':  None,\n",
    "        'text_cols':  ['Text'],\n",
    "        'label_col':  'Score',\n",
    "        'has_test_file': False\n",
    "    },\n",
    "    'imdb': {\n",
    "        'path': 'dataset/imdb-dataset-of-50k-movie-reviews',\n",
    "        'train_file': 'IMDB Dataset.csv',\n",
    "        'test_file':  None,\n",
    "        'text_cols':  ['review'],\n",
    "        'label_col':  'sentiment',\n",
    "        'label_transform': lambda x: 1 if x=='positive' else 0,\n",
    "        'has_test_file': False\n",
    "    }\n",
    "}\n",
    "\n",
    "cfg = configs[DATASET]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e24740c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imdb: #train=40000  #test=10000\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Load and split dataset\n",
    "# ────────────────────────────────\n",
    "\n",
    "# load train\n",
    "train_df = pd.read_csv(f\"{cfg['path']}/{cfg['train_file']}\")\n",
    "\n",
    "# build train_texts\n",
    "if len(cfg['text_cols']) > 1:\n",
    "    texts = train_df[cfg['text_cols'][0]].astype(str) + \" \" + train_df[cfg['text_cols'][1]].astype(str)\n",
    "else:\n",
    "    texts = train_df[cfg['text_cols'][0]].astype(str)\n",
    "\n",
    "# build train_labels\n",
    "if 'label_shift' in cfg:\n",
    "    labels = (train_df[cfg['label_col']] + cfg['label_shift']).tolist()\n",
    "elif 'label_transform' in cfg:\n",
    "    labels = train_df[cfg['label_col']].map(cfg['label_transform']).tolist()\n",
    "else:\n",
    "    labels = train_df[cfg['label_col']].tolist()\n",
    "\n",
    "# split into train/test\n",
    "if cfg['has_test_file']:\n",
    "    # built‐in test split\n",
    "    test_df = pd.read_csv(f\"{cfg['path']}/{cfg['test_file']}\")\n",
    "    if len(cfg['text_cols']) > 1:\n",
    "        test_texts = test_df[cfg['text_cols'][0]].astype(str) + \" \" + test_df[cfg['text_cols'][1]].astype(str)\n",
    "    else:\n",
    "        test_texts = test_df[cfg['text_cols'][0]].astype(str)\n",
    "    if 'label_shift' in cfg:\n",
    "        test_labels = (test_df[cfg['label_col']] + cfg['label_shift']).tolist()\n",
    "    elif 'label_transform' in cfg:\n",
    "        test_labels = test_df[cfg['label_col']].map(cfg['label_transform']).tolist()\n",
    "    else:\n",
    "        test_labels = test_df[cfg['label_col']].tolist()\n",
    "\n",
    "    train_texts = texts.tolist()\n",
    "    train_labels = labels\n",
    "else:\n",
    "    # sequential split: first (1–TEST_SIZE) for train, last TEST_SIZE for test\n",
    "    split_idx = int(len(texts) * (1 - TEST_SIZE))\n",
    "    train_texts = texts.tolist()[:split_idx]\n",
    "    train_labels = labels[:split_idx]\n",
    "    test_texts  = texts.tolist()[split_idx:]\n",
    "    test_labels = labels[split_idx:]\n",
    "\n",
    "print(f\"{DATASET}: #train={len(train_texts)}  #test={len(test_texts)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9eebe9b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (40000, 5000), X_test shape: (10000, 5000)\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Vectorize with TF‐IDF\n",
    "# ─────────────────────────────\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
    "X_train = vectorizer.fit_transform(train_texts)\n",
    "X_test  = vectorizer.transform(test_texts)\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}, X_test shape: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d38488d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            accuracy  error_rate  rel_err_reduction\n",
      "fraction_%                                         \n",
      "20            0.8663      0.1337           0.000000\n",
      "40            0.8777      0.1223           8.526552\n",
      "60            0.8803      0.1197          10.471204\n",
      "80            0.8836      0.1164          12.939417\n",
      "→ Saved ULMFiT‐style metrics to ./bow/imdb/results/bow_ulmfit_metrics.csv\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Summarize BoW results with ULMFiT‐style metrics\n",
    "# ───────────────────────────────────────────────────────\n",
    "\n",
    "fractions = [0.2, 0.4, 0.6, 0.8]\n",
    "rows = []\n",
    "baseline_frac = fractions[0]\n",
    "baseline_error = None\n",
    "\n",
    "for frac in fractions:\n",
    "    n = int(len(train_labels) * frac)\n",
    "    X_frac = X_train[:n]\n",
    "    y_frac = np.array(train_labels[:n])\n",
    "\n",
    "    clf = LogisticRegression(\n",
    "        max_iter=1_000,\n",
    "        random_state=42,\n",
    "        multi_class='multinomial',\n",
    "        solver='lbfgs'\n",
    "    )\n",
    "    clf.fit(X_frac, y_frac)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "    acc = accuracy_score(test_labels, y_pred)\n",
    "    err = 1.0 - acc\n",
    "    if frac == baseline_frac:\n",
    "        baseline_error = err\n",
    "    rel = (baseline_error - err) / baseline_error * 100 if baseline_error else 0.0\n",
    "\n",
    "    rows.append({\n",
    "        \"fraction_%\":        int(frac*100),\n",
    "        \"accuracy\":          acc,\n",
    "        \"error_rate\":        err,\n",
    "        \"rel_err_reduction\": rel\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(rows).set_index(\"fraction_%\")\n",
    "print(df)\n",
    "\n",
    "# save to CSV\n",
    "results_dir = f\"./bow/{DATASET}/results\"\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "output_path = os.path.join(results_dir, \"bow_ulmfit_metrics.csv\")\n",
    "df.to_csv(output_path)\n",
    "print(f\"→ Saved ULMFiT‐style metrics to {output_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
