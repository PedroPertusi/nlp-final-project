{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6979f431",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from gensim import corpora\n",
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Change this to 'amazon', 'ag', or 'imdb'\n",
    "# DATASET = 'amazon'\n",
    "# DATASET = 'ag'\n",
    "DATASET = 'amazon'\n",
    "\n",
    "TEST_SIZE = 0.2  # fraction for test set\n",
    "\n",
    "configs = {\n",
    "    'ag': {\n",
    "        'path': 'dataset/ag-news-classification-dataset',\n",
    "        'train_file': 'train.csv',\n",
    "        'test_file':  'test.csv',\n",
    "        'text_cols':  ['Title','Description'],\n",
    "        'label_col':  'Class Index',\n",
    "        'label_shift': -1,\n",
    "        'has_test_file': True\n",
    "    },\n",
    "    'amazon': {\n",
    "        'path': 'dataset/amazon-fine-food-reviews',\n",
    "        'train_file': 'Reviews.csv',\n",
    "        'test_file':  None,\n",
    "        'text_cols':  ['Text'],\n",
    "        'label_col':  'Score',\n",
    "        'has_test_file': False\n",
    "    },\n",
    "    'imdb': {\n",
    "        'path': 'dataset/imdb-dataset-of-50k-movie-reviews',\n",
    "        'train_file': 'IMDB Dataset.csv',\n",
    "        'test_file':  None,\n",
    "        'text_cols':  ['review'],\n",
    "        'label_col':  'sentiment',\n",
    "        'label_transform': lambda x: 1 if x=='positive' else 0,\n",
    "        'has_test_file': False\n",
    "    }\n",
    "}\n",
    "\n",
    "cfg = configs[DATASET]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "71fcc0e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amazon: #train=454763  #test=113691\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Load and split dataset\n",
    "# ────────────────────────────────\n",
    "\n",
    "# load train\n",
    "train_df = pd.read_csv(f\"{cfg['path']}/{cfg['train_file']}\")\n",
    "\n",
    "# build train_texts\n",
    "if len(cfg['text_cols']) > 1:\n",
    "    texts = train_df[cfg['text_cols'][0]].astype(str) + \" \" + train_df[cfg['text_cols'][1]].astype(str)\n",
    "else:\n",
    "    texts = train_df[cfg['text_cols'][0]].astype(str)\n",
    "\n",
    "# build train_labels\n",
    "if 'label_shift' in cfg:\n",
    "    labels = (train_df[cfg['label_col']] + cfg['label_shift']).tolist()\n",
    "elif 'label_transform' in cfg:\n",
    "    labels = train_df[cfg['label_col']].map(cfg['label_transform']).tolist()\n",
    "else:\n",
    "    labels = train_df[cfg['label_col']].tolist()\n",
    "\n",
    "# split into train/test\n",
    "if cfg['has_test_file']:\n",
    "    # built‐in test split\n",
    "    test_df = pd.read_csv(f\"{cfg['path']}/{cfg['test_file']}\")\n",
    "    if len(cfg['text_cols']) > 1:\n",
    "        test_texts = test_df[cfg['text_cols'][0]].astype(str) + \" \" + test_df[cfg['text_cols'][1]].astype(str)\n",
    "    else:\n",
    "        test_texts = test_df[cfg['text_cols'][0]].astype(str)\n",
    "    if 'label_shift' in cfg:\n",
    "        test_labels = (test_df[cfg['label_col']] + cfg['label_shift']).tolist()\n",
    "    elif 'label_transform' in cfg:\n",
    "        test_labels = test_df[cfg['label_col']].map(cfg['label_transform']).tolist()\n",
    "    else:\n",
    "        test_labels = test_df[cfg['label_col']].tolist()\n",
    "\n",
    "    train_texts = texts.tolist()\n",
    "    train_labels = labels\n",
    "else:\n",
    "    # sequential split: first (1–TEST_SIZE) for train, last TEST_SIZE for test\n",
    "    split_idx = int(len(texts) * (1 - TEST_SIZE))\n",
    "    train_texts = texts.tolist()[:split_idx]\n",
    "    train_labels = labels[:split_idx]\n",
    "    test_texts  = texts.tolist()[split_idx:]\n",
    "    test_labels = labels[split_idx:]\n",
    "\n",
    "print(f\"{DATASET}: #train={len(train_texts)}  #test={len(test_texts)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e14101d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/eduardo/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/eduardo/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/eduardo/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 3: Load data from nltk\n",
    "# ─────────────────────────────\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4e06d295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Defining pre-processing tools\n",
    "# ─────────────────────────────\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess(text):\n",
    "    text = re.sub(r'[^a-zA-Z]', ' ', text)\n",
    "    tokens = text.lower().split()\n",
    "    tokens = [lemmatizer.lemmatize(t) for t in tokens if t not in stop_words and len(t) > 2]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "72c1db82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Preprocess train data and Create train corpus\n",
    "# ─────────────────────────────\n",
    "\n",
    "processed_train = [preprocess(doc) for doc in train_texts]\n",
    "dictionary = corpora.Dictionary(processed_train)\n",
    "dictionary.filter_extremes(no_below=15, no_above=0.5, keep_n=20000)\n",
    "\n",
    "corpus_train = [dictionary.doc2bow(doc) for doc in processed_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a59638e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Define a function to extract the topic distribuition vector for\n",
    "# each document.\n",
    "# ─────────────────────────────\n",
    "\n",
    "def get_topic_vector(doc, model):\n",
    "    bow = dictionary.doc2bow(preprocess(doc))\n",
    "    topic_dist = model.get_document_topics(bow, minimum_probability=0)\n",
    "    vec = np.zeros(10)\n",
    "    for idx, prob in topic_dist:\n",
    "        vec[idx] = prob\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffb1aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.6456\n",
      "Test accuracy: 0.6461\n",
      "Test accuracy: 0.6458\n",
      "Test accuracy: 0.6460\n",
      "            accuracy  error_rate  rel_err_reduction\n",
      "fraction_%                                         \n",
      "20          0.645645    0.354355           0.000000\n",
      "40          0.646093    0.353907           0.126592\n",
      "60          0.645838    0.354162           0.054608\n",
      "80          0.646023    0.353977           0.106734\n",
      "→ Saved ULMFiT‐style metrics to ./lda/amazon/results/lda_ulmfit_metrics.csv\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Summarize LDA results with ULMFiT‐style metrics\n",
    "# ───────────────────────────────────────────────────────\n",
    "\n",
    "fractions = [0.2, 0.4, 0.6, 0.8]\n",
    "rows = []\n",
    "baseline_frac = fractions[0]\n",
    "baseline_error = None\n",
    "\n",
    "for frac in fractions:\n",
    "    n = int(len(train_labels) * frac)\n",
    "    X_frac = X_train[:n]\n",
    "    corpus_frac = corpus_train[:n]\n",
    "    y_frac = np.array(train_labels[:n])\n",
    "\n",
    "    \n",
    "    lda_model = LdaMulticore(corpus=corpus_frac,\n",
    "                         id2word=dictionary,\n",
    "                         num_topics=10,\n",
    "                         passes=10,\n",
    "                         workers=2,\n",
    "                         random_state=42,\n",
    "                         chunksize=100)\n",
    "\n",
    "    X_train = np.array([get_topic_vector(doc, lda_model) for doc in train_texts])\n",
    "    X_test = np.array([get_topic_vector(doc, lda_model) for doc in test_texts])\n",
    "\n",
    "    clf = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000, random_state=42)\n",
    "    clf.fit(X_train, train_labels)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "    acc = accuracy_score(test_labels, y_pred)\n",
    "    print(f\"Test accuracy: {acc:.4f}\")\n",
    "\n",
    "    acc = accuracy_score(test_labels, y_pred)\n",
    "    err = 1.0 - acc\n",
    "    if frac == baseline_frac:\n",
    "        baseline_error = err\n",
    "    rel = (baseline_error - err) / baseline_error * 100 if baseline_error else 0.0\n",
    "\n",
    "    rows.append({\n",
    "        \"fraction_%\":        int(frac*100),\n",
    "        \"accuracy\":          acc,\n",
    "        \"error_rate\":        err,\n",
    "        \"rel_err_reduction\": rel\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(rows).set_index(\"fraction_%\")\n",
    "print(df)\n",
    "\n",
    "# save to CSV\n",
    "results_dir = f\"./lda/{DATASET}/results\"\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "output_path = os.path.join(results_dir, \"lda_ulmfit_metrics.csv\")\n",
    "df.to_csv(output_path)\n",
    "print(f\"→ Saved ULMFiT‐style metrics to {output_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
